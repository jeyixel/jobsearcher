import asyncio
import logging
import os
import sys
import firebase_admin
from firebase_admin import credentials, firestore, messaging
from scraper import scrape_jobhub, scrape_itpro, scrape_Devjobs # Importing your functions

# 1. INITIALIZE FIREBASE
# You must have 'serviceAccountKey.json' in this folder.
if not firebase_admin._apps: # this line prevents re-initialization error by checking if already initialized
    key_path = "serviceAccountKey.json"
    if not os.path.exists(key_path):
        print("‚ùå serviceAccountKey.json not found. Place the file in the scraper folder.")
        sys.exit(1)
    cred = credentials.Certificate(key_path) # reads the service account key and returns a credential object
    firebase_admin.initialize_app(cred) # initializes the Firebase app with the given credentials

db = firestore.client()

def get_existing_job_ids():
    """
    Fetches all document IDs from the 'internships' collection.
    Returns a set of IDs for fast comparison.
    """
    print("Fetching existing jobs from Firestore...")
    
    try:
        docs = db.collection("internships").stream()
        # We use a set() because looking up items in a set is instant (O(1))
        return {doc.id for doc in docs}
    except Exception as e:
        print(f"‚ùå Error fetching existing jobs: {e}")
        return set() # Return empty set on error

def send_push_notification(new_jobs_count, sample_job):
    """
    Sends a push notification to all devices subscribed to the 'internships' topic.
    """
    topic = "internships"
    
    # Custom message logic
    if new_jobs_count == 1:
        title = "New Internship Alert! üöÄ"
        body = f"{sample_job['company']} is looking for a {sample_job['job_title']}"
    else:
        title = f"{new_jobs_count} New Internships Found!"
        body = f"Check out roles at {sample_job['company']} and others."

    # Create the message payload
    message = messaging.Message(
        notification=messaging.Notification(
            title=title,
            body=body,
        ),
        data={
            "click_action": "FLUTTER_NOTIFICATION_CLICK",
            "screen": "Home", # Example: Tell app to open Home screen
        },
        topic=topic,
    )

    # Send
    try:
        response = messaging.send(message)
        print(f"‚úÖ Notification sent: {response}")
    except Exception as e:
        print(f"‚ùå Error sending notification: {e}")

async def run_bot():
    print("\n=== STARTING BOT ORCHESTRATOR ===")
    
    # 1. GET OLD STATE
    try:
        existing_ids = get_existing_job_ids()
        print(f"Existing jobs in DB: {len(existing_ids)}")
    except Exception as e:
        print(f"‚ùå Failed to get existing job IDs: {e}")
        existing_ids = set()  # Fallback to empty set
        print("Proceeding with empty existing IDs set.")

    # 2. GET NEW STATE (Scrape)
    print("Running scrapers...")
    results = await asyncio.gather(
        scrape_jobhub(),
        scrape_itpro(),
        scrape_Devjobs()
    )
    # Combine lists
    scraped_jobs = results[0] + results[1] + results[2]
    print(f"Total new jobs scraped: {len(scraped_jobs)}")

    # 3. COMPARE (Diffing)
    new_jobs_found = []

    # Batch write for performance (commit in chunks to avoid limits)
    batch = db.batch()
    batch_counter = 0

    # Diagnostics
    skipped_existing = 0
    duplicate_in_scrape = 0
    seen_in_loop = set()

    for job in scraped_jobs:
        job_id = job.get('id')
        if not job_id:
            # Skip invalid job entries
            print(f"‚ö†Ô∏è Skipping job with missing id: {job}")
            continue

        # Track duplicates inside this scrape
        if job_id in seen_in_loop:
            duplicate_in_scrape += 1
            continue
        seen_in_loop.add(job_id)

        # If this ID is NOT in our existing set, it's NEW.
        if job_id not in existing_ids:
            new_jobs_found.append(job)

            # Add to Firestore Batch
            doc_ref = db.collection("internships").document(job_id)
            batch.set(doc_ref, job)
            batch_counter += 1

            # Commit periodically to respect Firestore limits and reduce memory
            if batch_counter >= 400:
                try:
                    batch.commit()
                    print(f"üîÅ Committed a chunk of {batch_counter} writes to Firestore.")
                except Exception as e:
                    print(f"‚ùå Error committing batch chunk: {e}")
                batch = db.batch()
                batch_counter = 0
        else:
            skipped_existing += 1

    # 4. SAVE & NOTIFY
    if new_jobs_found:
        print(f"üöÄ Found {len(new_jobs_found)} NEW jobs!")
        print(f"‚ÑπÔ∏è Skipped {skipped_existing} jobs already in Firestore.")
        if duplicate_in_scrape:
            print(f"‚ÑπÔ∏è Ignored {duplicate_in_scrape} duplicate IDs inside the scrape.")

        # Commit any remaining writes
        try:
            if batch_counter > 0:
                batch.commit()
                print(f"‚úÖ Committed final chunk of {batch_counter} writes to Firestore.")
        except Exception as e:
            print(f"‚ùå Error committing final batch: {e}")
        else:
            print("‚úÖ New jobs saved to Firestore.")

        # Trigger FCM Notification
        # We send one notification summarizing the update
        send_push_notification(len(new_jobs_found), new_jobs_found[0])
        
    else:
        print("üí§ No new jobs found. Database is up to date.")

if __name__ == "__main__":
    asyncio.run(run_bot())